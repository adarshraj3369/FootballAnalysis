{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhxqisgwYs3EfL/QFvX2A9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshraj3369/FootballAnalysis/blob/Develop/yolo_inference_yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tltCmq7gPXyd",
        "outputId": "5f4550b4-8777-434f-e9e6-640afc334b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.58-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.7/802.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.58 ultralytics-thop-2.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8x')\n",
        "results = model.predict('input_videos/08fd33_4.mp4',save=True)\n",
        "print(results[0])\n",
        "\n",
        "print(\"###############################################\\n\")\n",
        "for box in results[0].boxes:\n",
        "    print(box)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ2UJW6xQOqK",
        "outputId": "bd948663-ad25-4870-db73-93637c19ac9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 363MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 79.2ms\n",
            "video 1/1 (frame 2/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 54.8ms\n",
            "video 1/1 (frame 3/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 54.8ms\n",
            "video 1/1 (frame 4/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 54.8ms\n",
            "video 1/1 (frame 5/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 42.0ms\n",
            "video 1/1 (frame 6/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 42.1ms\n",
            "video 1/1 (frame 7/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 40.1ms\n",
            "video 1/1 (frame 8/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 40.1ms\n",
            "video 1/1 (frame 9/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 39.9ms\n",
            "video 1/1 (frame 10/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 39.4ms\n",
            "video 1/1 (frame 11/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 39.0ms\n",
            "video 1/1 (frame 12/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 39.0ms\n",
            "video 1/1 (frame 13/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 39.1ms\n",
            "video 1/1 (frame 14/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 39.0ms\n",
            "video 1/1 (frame 15/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 44.1ms\n",
            "video 1/1 (frame 16/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 39.0ms\n",
            "video 1/1 (frame 17/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 39.0ms\n",
            "video 1/1 (frame 18/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.0ms\n",
            "video 1/1 (frame 19/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.0ms\n",
            "video 1/1 (frame 20/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 38.9ms\n",
            "video 1/1 (frame 21/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 39.0ms\n",
            "video 1/1 (frame 22/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 43.0ms\n",
            "video 1/1 (frame 23/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 39.0ms\n",
            "video 1/1 (frame 24/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 41.0ms\n",
            "video 1/1 (frame 25/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 41.0ms\n",
            "video 1/1 (frame 26/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 40.2ms\n",
            "video 1/1 (frame 27/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 39.9ms\n",
            "video 1/1 (frame 28/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 29/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 39.9ms\n",
            "video 1/1 (frame 30/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 31/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 42.9ms\n",
            "video 1/1 (frame 32/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 33/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 34/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 35/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 36/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 37/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 38/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 39.6ms\n",
            "video 1/1 (frame 39/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 sports ball, 1 tv, 39.6ms\n",
            "video 1/1 (frame 40/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 sports ball, 1 tv, 40.1ms\n",
            "video 1/1 (frame 41/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 sports ball, 1 tv, 39.9ms\n",
            "video 1/1 (frame 42/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.4ms\n",
            "video 1/1 (frame 43/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.0ms\n",
            "video 1/1 (frame 44/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 38.9ms\n",
            "video 1/1 (frame 45/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 1 tv, 39.8ms\n",
            "video 1/1 (frame 46/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 38.9ms\n",
            "video 1/1 (frame 47/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 38.7ms\n",
            "video 1/1 (frame 48/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 38.7ms\n",
            "video 1/1 (frame 49/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 50/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 51/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.7ms\n",
            "video 1/1 (frame 52/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 53/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.7ms\n",
            "video 1/1 (frame 54/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 55/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 38.7ms\n",
            "video 1/1 (frame 56/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 38.6ms\n",
            "video 1/1 (frame 57/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 38.7ms\n",
            "video 1/1 (frame 58/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 38.7ms\n",
            "video 1/1 (frame 59/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 60/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 61/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 38.6ms\n",
            "video 1/1 (frame 62/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 38.7ms\n",
            "video 1/1 (frame 63/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 38.7ms\n",
            "video 1/1 (frame 64/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 38.6ms\n",
            "video 1/1 (frame 65/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 38.6ms\n",
            "video 1/1 (frame 66/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 38.6ms\n",
            "video 1/1 (frame 67/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 68/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 38.7ms\n",
            "video 1/1 (frame 69/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 38.7ms\n",
            "video 1/1 (frame 70/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 38.6ms\n",
            "video 1/1 (frame 71/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 37.5ms\n",
            "video 1/1 (frame 72/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 36.4ms\n",
            "video 1/1 (frame 73/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 36.4ms\n",
            "video 1/1 (frame 74/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 36.4ms\n",
            "video 1/1 (frame 75/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 36.4ms\n",
            "video 1/1 (frame 76/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 36.4ms\n",
            "video 1/1 (frame 77/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 1 tv, 35.8ms\n",
            "video 1/1 (frame 78/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 34.6ms\n",
            "video 1/1 (frame 79/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 33.5ms\n",
            "video 1/1 (frame 80/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 33.9ms\n",
            "video 1/1 (frame 81/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 33.0ms\n",
            "video 1/1 (frame 82/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 32.9ms\n",
            "video 1/1 (frame 83/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.0ms\n",
            "video 1/1 (frame 84/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 33.9ms\n",
            "video 1/1 (frame 85/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 33.0ms\n",
            "video 1/1 (frame 86/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.9ms\n",
            "video 1/1 (frame 87/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 33.5ms\n",
            "video 1/1 (frame 88/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 33.9ms\n",
            "video 1/1 (frame 89/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 33.1ms\n",
            "video 1/1 (frame 90/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 33.9ms\n",
            "video 1/1 (frame 91/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 33.0ms\n",
            "video 1/1 (frame 92/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 33.7ms\n",
            "video 1/1 (frame 93/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 32.6ms\n",
            "video 1/1 (frame 94/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 32.6ms\n",
            "video 1/1 (frame 95/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 32.6ms\n",
            "video 1/1 (frame 96/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 32.2ms\n",
            "video 1/1 (frame 97/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 32.7ms\n",
            "video 1/1 (frame 98/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 32.3ms\n",
            "video 1/1 (frame 99/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 32.6ms\n",
            "video 1/1 (frame 100/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 32.2ms\n",
            "video 1/1 (frame 101/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 1 tv, 32.6ms\n",
            "video 1/1 (frame 102/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 32.2ms\n",
            "video 1/1 (frame 103/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.3ms\n",
            "video 1/1 (frame 104/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 sports ball, 32.3ms\n",
            "video 1/1 (frame 105/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 sports ball, 32.6ms\n",
            "video 1/1 (frame 106/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 32.2ms\n",
            "video 1/1 (frame 107/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 32.6ms\n",
            "video 1/1 (frame 108/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 32.6ms\n",
            "video 1/1 (frame 109/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 32.2ms\n",
            "video 1/1 (frame 110/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 32.6ms\n",
            "video 1/1 (frame 111/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 32.6ms\n",
            "video 1/1 (frame 112/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 32.2ms\n",
            "video 1/1 (frame 113/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 1 tv, 29.4ms\n",
            "video 1/1 (frame 114/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 sports ball, 1 tv, 29.8ms\n",
            "video 1/1 (frame 115/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 1 tv, 29.5ms\n",
            "video 1/1 (frame 116/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 sports ball, 1 tv, 29.4ms\n",
            "video 1/1 (frame 117/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.7ms\n",
            "video 1/1 (frame 118/750) /content/input_videos/08fd33_4.mp4: 384x640 20 persons, 1 tv, 29.8ms\n",
            "video 1/1 (frame 119/750) /content/input_videos/08fd33_4.mp4: 384x640 18 persons, 1 tv, 29.7ms\n",
            "video 1/1 (frame 120/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 29.8ms\n",
            "video 1/1 (frame 121/750) /content/input_videos/08fd33_4.mp4: 384x640 20 persons, 1 tv, 29.3ms\n",
            "video 1/1 (frame 122/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 29.4ms\n",
            "video 1/1 (frame 123/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 29.4ms\n",
            "video 1/1 (frame 124/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.7ms\n",
            "video 1/1 (frame 125/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.7ms\n",
            "video 1/1 (frame 126/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 29.4ms\n",
            "video 1/1 (frame 127/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 29.6ms\n",
            "video 1/1 (frame 128/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 29.5ms\n",
            "video 1/1 (frame 129/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 1 sports ball, 1 tv, 29.9ms\n",
            "video 1/1 (frame 130/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 sports ball, 1 chair, 1 tv, 29.7ms\n",
            "video 1/1 (frame 131/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 29.8ms\n",
            "video 1/1 (frame 132/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.9ms\n",
            "video 1/1 (frame 133/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.6ms\n",
            "video 1/1 (frame 134/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 1 tv, 30.0ms\n",
            "video 1/1 (frame 135/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 29.5ms\n",
            "video 1/1 (frame 136/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.6ms\n",
            "video 1/1 (frame 137/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 30.0ms\n",
            "video 1/1 (frame 138/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 1 sports ball, 29.5ms\n",
            "video 1/1 (frame 139/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 29.5ms\n",
            "video 1/1 (frame 140/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 29.6ms\n",
            "video 1/1 (frame 141/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 30.1ms\n",
            "video 1/1 (frame 142/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 29.5ms\n",
            "video 1/1 (frame 143/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 29.8ms\n",
            "video 1/1 (frame 144/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 37.1ms\n",
            "video 1/1 (frame 145/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 36.0ms\n",
            "video 1/1 (frame 146/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 37.3ms\n",
            "video 1/1 (frame 147/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 37.8ms\n",
            "video 1/1 (frame 148/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 37.8ms\n",
            "video 1/1 (frame 149/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 sports ball, 37.8ms\n",
            "video 1/1 (frame 150/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 38.4ms\n",
            "video 1/1 (frame 151/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 44.4ms\n",
            "video 1/1 (frame 152/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 43.4ms\n",
            "video 1/1 (frame 153/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 40.6ms\n",
            "video 1/1 (frame 154/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 41.0ms\n",
            "video 1/1 (frame 155/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 41.0ms\n",
            "video 1/1 (frame 156/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 42.6ms\n",
            "video 1/1 (frame 157/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 42.6ms\n",
            "video 1/1 (frame 158/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 40.7ms\n",
            "video 1/1 (frame 159/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 40.6ms\n",
            "video 1/1 (frame 160/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 40.2ms\n",
            "video 1/1 (frame 161/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 39.9ms\n",
            "video 1/1 (frame 162/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.6ms\n",
            "video 1/1 (frame 163/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 sports ball, 39.6ms\n",
            "video 1/1 (frame 164/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 39.6ms\n",
            "video 1/1 (frame 165/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 sports ball, 39.6ms\n",
            "video 1/1 (frame 166/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.6ms\n",
            "video 1/1 (frame 167/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 39.6ms\n",
            "video 1/1 (frame 168/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 39.6ms\n",
            "video 1/1 (frame 169/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 39.6ms\n",
            "video 1/1 (frame 170/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.6ms\n",
            "video 1/1 (frame 171/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.6ms\n",
            "video 1/1 (frame 172/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.6ms\n",
            "video 1/1 (frame 173/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 39.6ms\n",
            "video 1/1 (frame 174/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.6ms\n",
            "video 1/1 (frame 175/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 39.6ms\n",
            "video 1/1 (frame 176/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.5ms\n",
            "video 1/1 (frame 177/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.6ms\n",
            "video 1/1 (frame 178/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.6ms\n",
            "video 1/1 (frame 179/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.6ms\n",
            "video 1/1 (frame 180/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 40.0ms\n",
            "video 1/1 (frame 181/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 39.4ms\n",
            "video 1/1 (frame 182/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 39.0ms\n",
            "video 1/1 (frame 183/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.0ms\n",
            "video 1/1 (frame 184/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 38.9ms\n",
            "video 1/1 (frame 185/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 39.0ms\n",
            "video 1/1 (frame 186/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 38.9ms\n",
            "video 1/1 (frame 187/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 39.0ms\n",
            "video 1/1 (frame 188/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.6ms\n",
            "video 1/1 (frame 189/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 39.7ms\n",
            "video 1/1 (frame 190/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 37.9ms\n",
            "video 1/1 (frame 191/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 37.0ms\n",
            "video 1/1 (frame 192/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 36.9ms\n",
            "video 1/1 (frame 193/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 36.9ms\n",
            "video 1/1 (frame 194/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 36.9ms\n",
            "video 1/1 (frame 195/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 36.9ms\n",
            "video 1/1 (frame 196/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 39.0ms\n",
            "video 1/1 (frame 197/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 36.9ms\n",
            "video 1/1 (frame 198/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 37.0ms\n",
            "video 1/1 (frame 199/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 36.9ms\n",
            "video 1/1 (frame 200/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 36.9ms\n",
            "video 1/1 (frame 201/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 37.6ms\n",
            "video 1/1 (frame 202/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 36.9ms\n",
            "video 1/1 (frame 203/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 1 tv, 36.9ms\n",
            "video 1/1 (frame 204/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 36.9ms\n",
            "video 1/1 (frame 205/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 tv, 36.9ms\n",
            "video 1/1 (frame 206/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 37.0ms\n",
            "video 1/1 (frame 207/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 36.9ms\n",
            "video 1/1 (frame 208/750) /content/input_videos/08fd33_4.mp4: 384x640 29 persons, 1 tv, 38.1ms\n",
            "video 1/1 (frame 209/750) /content/input_videos/08fd33_4.mp4: 384x640 29 persons, 1 tv, 37.9ms\n",
            "video 1/1 (frame 210/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 38.9ms\n",
            "video 1/1 (frame 211/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.7ms\n",
            "video 1/1 (frame 212/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 38.1ms\n",
            "video 1/1 (frame 213/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.8ms\n",
            "video 1/1 (frame 214/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 37.7ms\n",
            "video 1/1 (frame 215/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.8ms\n",
            "video 1/1 (frame 216/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.8ms\n",
            "video 1/1 (frame 217/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.7ms\n",
            "video 1/1 (frame 218/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.7ms\n",
            "video 1/1 (frame 219/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 37.7ms\n",
            "video 1/1 (frame 220/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 39.0ms\n",
            "video 1/1 (frame 221/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 38.1ms\n",
            "video 1/1 (frame 222/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 38.0ms\n",
            "video 1/1 (frame 223/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 1 tv, 38.1ms\n",
            "video 1/1 (frame 224/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 38.0ms\n",
            "video 1/1 (frame 225/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 38.0ms\n",
            "video 1/1 (frame 226/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.6ms\n",
            "video 1/1 (frame 227/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 38.0ms\n",
            "video 1/1 (frame 228/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.7ms\n",
            "video 1/1 (frame 229/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 37.7ms\n",
            "video 1/1 (frame 230/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 38.3ms\n",
            "video 1/1 (frame 231/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 38.2ms\n",
            "video 1/1 (frame 232/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 36.9ms\n",
            "video 1/1 (frame 233/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 36.1ms\n",
            "video 1/1 (frame 234/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 35.8ms\n",
            "video 1/1 (frame 235/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 35.7ms\n",
            "video 1/1 (frame 236/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 35.4ms\n",
            "video 1/1 (frame 237/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 34.0ms\n",
            "video 1/1 (frame 238/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.3ms\n",
            "video 1/1 (frame 239/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 34.0ms\n",
            "video 1/1 (frame 240/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 33.2ms\n",
            "video 1/1 (frame 241/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.3ms\n",
            "video 1/1 (frame 242/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 34.0ms\n",
            "video 1/1 (frame 243/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 33.3ms\n",
            "video 1/1 (frame 244/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 33.2ms\n",
            "video 1/1 (frame 245/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 33.3ms\n",
            "video 1/1 (frame 246/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 34.0ms\n",
            "video 1/1 (frame 247/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.2ms\n",
            "video 1/1 (frame 248/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 35.0ms\n",
            "video 1/1 (frame 249/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 34.1ms\n",
            "video 1/1 (frame 250/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 33.2ms\n",
            "video 1/1 (frame 251/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 33.2ms\n",
            "video 1/1 (frame 252/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 33.3ms\n",
            "video 1/1 (frame 253/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 33.4ms\n",
            "video 1/1 (frame 254/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 33.2ms\n",
            "video 1/1 (frame 255/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.9ms\n",
            "video 1/1 (frame 256/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.2ms\n",
            "video 1/1 (frame 257/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 baseball bat, 32.3ms\n",
            "video 1/1 (frame 258/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 31.6ms\n",
            "video 1/1 (frame 259/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.3ms\n",
            "video 1/1 (frame 260/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 32.3ms\n",
            "video 1/1 (frame 261/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.2ms\n",
            "video 1/1 (frame 262/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 32.3ms\n",
            "video 1/1 (frame 263/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.2ms\n",
            "video 1/1 (frame 264/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.4ms\n",
            "video 1/1 (frame 265/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.3ms\n",
            "video 1/1 (frame 266/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.2ms\n",
            "video 1/1 (frame 267/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.2ms\n",
            "video 1/1 (frame 268/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.0ms\n",
            "video 1/1 (frame 269/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.7ms\n",
            "video 1/1 (frame 270/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.3ms\n",
            "video 1/1 (frame 271/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 38.3ms\n",
            "video 1/1 (frame 272/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 40.9ms\n",
            "video 1/1 (frame 273/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 44.2ms\n",
            "video 1/1 (frame 274/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 38.9ms\n",
            "video 1/1 (frame 275/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 41.2ms\n",
            "video 1/1 (frame 276/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 41.0ms\n",
            "video 1/1 (frame 277/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 43.3ms\n",
            "video 1/1 (frame 278/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 39.8ms\n",
            "video 1/1 (frame 279/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 39.6ms\n",
            "video 1/1 (frame 280/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 39.2ms\n",
            "video 1/1 (frame 281/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 35.2ms\n",
            "video 1/1 (frame 282/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 34.3ms\n",
            "video 1/1 (frame 283/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 34.4ms\n",
            "video 1/1 (frame 284/750) /content/input_videos/08fd33_4.mp4: 384x640 18 persons, 34.3ms\n",
            "video 1/1 (frame 285/750) /content/input_videos/08fd33_4.mp4: 384x640 17 persons, 34.4ms\n",
            "video 1/1 (frame 286/750) /content/input_videos/08fd33_4.mp4: 384x640 20 persons, 34.4ms\n",
            "video 1/1 (frame 287/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 34.4ms\n",
            "video 1/1 (frame 288/750) /content/input_videos/08fd33_4.mp4: 384x640 21 persons, 34.4ms\n",
            "video 1/1 (frame 289/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 34.3ms\n",
            "video 1/1 (frame 290/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 34.3ms\n",
            "video 1/1 (frame 291/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 34.4ms\n",
            "video 1/1 (frame 292/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.3ms\n",
            "video 1/1 (frame 293/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 34.4ms\n",
            "video 1/1 (frame 294/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 34.4ms\n",
            "video 1/1 (frame 295/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 34.4ms\n",
            "video 1/1 (frame 296/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.4ms\n",
            "video 1/1 (frame 297/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.4ms\n",
            "video 1/1 (frame 298/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 34.5ms\n",
            "video 1/1 (frame 299/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 33.6ms\n",
            "video 1/1 (frame 300/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 32.3ms\n",
            "video 1/1 (frame 301/750) /content/input_videos/08fd33_4.mp4: 384x640 23 persons, 32.3ms\n",
            "video 1/1 (frame 302/750) /content/input_videos/08fd33_4.mp4: 384x640 22 persons, 32.0ms\n",
            "video 1/1 (frame 303/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.0ms\n",
            "video 1/1 (frame 304/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 32.3ms\n",
            "video 1/1 (frame 305/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.5ms\n",
            "video 1/1 (frame 306/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 32.3ms\n",
            "video 1/1 (frame 307/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 32.0ms\n",
            "video 1/1 (frame 308/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.3ms\n",
            "video 1/1 (frame 309/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.0ms\n",
            "video 1/1 (frame 310/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.3ms\n",
            "video 1/1 (frame 311/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 31.9ms\n",
            "video 1/1 (frame 312/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.3ms\n",
            "video 1/1 (frame 313/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 32.0ms\n",
            "video 1/1 (frame 314/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 32.3ms\n",
            "video 1/1 (frame 315/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 32.1ms\n",
            "video 1/1 (frame 316/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.3ms\n",
            "video 1/1 (frame 317/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.3ms\n",
            "video 1/1 (frame 318/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.7ms\n",
            "video 1/1 (frame 319/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 33.4ms\n",
            "video 1/1 (frame 320/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 32.8ms\n",
            "video 1/1 (frame 321/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 33.9ms\n",
            "video 1/1 (frame 322/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 33.0ms\n",
            "video 1/1 (frame 323/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.6ms\n",
            "video 1/1 (frame 324/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 33.6ms\n",
            "video 1/1 (frame 325/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 34.5ms\n",
            "video 1/1 (frame 326/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 sports ball, 34.2ms\n",
            "video 1/1 (frame 327/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 34.2ms\n",
            "video 1/1 (frame 328/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.5ms\n",
            "video 1/1 (frame 329/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 33.6ms\n",
            "video 1/1 (frame 330/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 tv, 32.2ms\n",
            "video 1/1 (frame 331/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 tv, 32.3ms\n",
            "video 1/1 (frame 332/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.2ms\n",
            "video 1/1 (frame 333/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 31.6ms\n",
            "video 1/1 (frame 334/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 32.2ms\n",
            "video 1/1 (frame 335/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 31.7ms\n",
            "video 1/1 (frame 336/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 31.6ms\n",
            "video 1/1 (frame 337/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 31.6ms\n",
            "video 1/1 (frame 338/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 32.4ms\n",
            "video 1/1 (frame 339/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 31.6ms\n",
            "video 1/1 (frame 340/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 32.2ms\n",
            "video 1/1 (frame 341/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 33.0ms\n",
            "video 1/1 (frame 342/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 32.3ms\n",
            "video 1/1 (frame 343/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 tv, 32.3ms\n",
            "video 1/1 (frame 344/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 32.2ms\n",
            "video 1/1 (frame 345/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 31.8ms\n",
            "video 1/1 (frame 346/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 32.2ms\n",
            "video 1/1 (frame 347/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 32.3ms\n",
            "video 1/1 (frame 348/750) /content/input_videos/08fd33_4.mp4: 384x640 29 persons, 1 tv, 32.5ms\n",
            "video 1/1 (frame 349/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 tv, 36.0ms\n",
            "video 1/1 (frame 350/750) /content/input_videos/08fd33_4.mp4: 384x640 28 persons, 1 tv, 34.7ms\n",
            "video 1/1 (frame 351/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 34.0ms\n",
            "video 1/1 (frame 352/750) /content/input_videos/08fd33_4.mp4: 384x640 24 persons, 1 tv, 35.2ms\n",
            "video 1/1 (frame 353/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 34.3ms\n",
            "video 1/1 (frame 354/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 35.7ms\n",
            "video 1/1 (frame 355/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 34.5ms\n",
            "video 1/1 (frame 356/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 35.8ms\n",
            "video 1/1 (frame 357/750) /content/input_videos/08fd33_4.mp4: 384x640 27 persons, 1 tv, 37.1ms\n",
            "video 1/1 (frame 358/750) /content/input_videos/08fd33_4.mp4: 384x640 26 persons, 1 tv, 36.1ms\n",
            "video 1/1 (frame 359/750) /content/input_videos/08fd33_4.mp4: 384x640 25 persons, 1 tv, 37.4ms\n",
            "Speed: 3.4ms preprocess, 36.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
            "obb: None\n",
            "orig_img: array([[[100, 146, 105],\n",
            "        [ 92, 138,  97],\n",
            "        [ 97, 150, 101],\n",
            "        ...,\n",
            "        [100,  92,  82],\n",
            "        [103,  95,  85],\n",
            "        [105,  97,  87]],\n",
            "\n",
            "       [[ 99, 145, 104],\n",
            "        [ 99, 145, 104],\n",
            "        [109, 162, 113],\n",
            "        ...,\n",
            "        [105,  97,  87],\n",
            "        [107,  99,  89],\n",
            "        [108, 100,  90]],\n",
            "\n",
            "       [[ 96, 149, 100],\n",
            "        [105, 158, 109],\n",
            "        [112, 170, 113],\n",
            "        ...,\n",
            "        [106,  98,  88],\n",
            "        [108, 100,  90],\n",
            "        [110, 102,  92]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 74, 103,  78],\n",
            "        [ 74, 103,  78],\n",
            "        [ 74, 103,  78],\n",
            "        ...,\n",
            "        [ 30,  47,  43],\n",
            "        [ 31,  48,  44],\n",
            "        [ 31,  48,  44]],\n",
            "\n",
            "       [[ 74, 103,  78],\n",
            "        [ 74, 103,  78],\n",
            "        [ 74, 103,  78],\n",
            "        ...,\n",
            "        [ 44,  56,  55],\n",
            "        [ 46,  58,  57],\n",
            "        [ 46,  58,  57]],\n",
            "\n",
            "       [[ 74, 103,  78],\n",
            "        [ 74, 103,  78],\n",
            "        [ 74, 103,  78],\n",
            "        ...,\n",
            "        [ 48,  60,  59],\n",
            "        [ 49,  61,  60],\n",
            "        [ 49,  61,  60]]], dtype=uint8)\n",
            "orig_shape: (1080, 1920)\n",
            "path: '/content/input_videos/08fd33_4.mp4'\n",
            "probs: None\n",
            "save_dir: 'runs/detect/predict'\n",
            "speed: {'preprocess': 12.994766235351562, 'inference': 79.15782928466797, 'postprocess': 901.2668132781982}\n",
            "###############################################\n",
            "\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8626], device='cuda:0')\n",
            "data: tensor([[533.7255, 686.3998, 579.3202, 784.5262,   0.8626,   0.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[556.5228, 735.4630,  45.5947,  98.1264]], device='cuda:0')\n",
            "xywhn: tensor([[0.2899, 0.6810, 0.0237, 0.0909]], device='cuda:0')\n",
            "xyxy: tensor([[533.7255, 686.3998, 579.3202, 784.5262]], device='cuda:0')\n",
            "xyxyn: tensor([[0.2780, 0.6356, 0.3017, 0.7264]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8573], device='cuda:0')\n",
            "data: tensor([[8.5193e+02, 6.3430e+02, 9.0102e+02, 7.2251e+02, 8.5730e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[876.4728, 678.4053,  49.0884,  88.2054]], device='cuda:0')\n",
            "xywhn: tensor([[0.4565, 0.6282, 0.0256, 0.0817]], device='cuda:0')\n",
            "xyxy: tensor([[851.9286, 634.3026, 901.0170, 722.5080]], device='cuda:0')\n",
            "xyxyn: tensor([[0.4437, 0.5873, 0.4693, 0.6690]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8546], device='cuda:0')\n",
            "data: tensor([[9.9466e+02, 4.5441e+02, 1.0276e+03, 5.2572e+02, 8.5460e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1011.1212,  490.0633,   32.9270,   71.3070]], device='cuda:0')\n",
            "xywhn: tensor([[0.5266, 0.4538, 0.0171, 0.0660]], device='cuda:0')\n",
            "xyxy: tensor([[ 994.6577,  454.4098, 1027.5847,  525.7168]], device='cuda:0')\n",
            "xyxyn: tensor([[0.5181, 0.4207, 0.5352, 0.4868]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8426], device='cuda:0')\n",
            "data: tensor([[1.3691e+03, 8.1410e+02, 1.4442e+03, 9.0364e+02, 8.4263e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1406.6117,  858.8718,   75.1135,   89.5393]], device='cuda:0')\n",
            "xywhn: tensor([[0.7326, 0.7953, 0.0391, 0.0829]], device='cuda:0')\n",
            "xyxy: tensor([[1369.0549,  814.1021, 1444.1685,  903.6414]], device='cuda:0')\n",
            "xyxyn: tensor([[0.7130, 0.7538, 0.7522, 0.8367]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8392], device='cuda:0')\n",
            "data: tensor([[1.5706e+03, 6.1067e+02, 1.6141e+03, 6.9612e+02, 8.3923e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1592.3397,  653.3976,   43.5217,   85.4520]], device='cuda:0')\n",
            "xywhn: tensor([[0.8293, 0.6050, 0.0227, 0.0791]], device='cuda:0')\n",
            "xyxy: tensor([[1570.5789,  610.6716, 1614.1006,  696.1235]], device='cuda:0')\n",
            "xyxyn: tensor([[0.8180, 0.5654, 0.8407, 0.6446]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8314], device='cuda:0')\n",
            "data: tensor([[1.3093e+03, 4.4540e+02, 1.3518e+03, 5.1765e+02, 8.3144e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1330.5193,  481.5244,   42.4790,   72.2520]], device='cuda:0')\n",
            "xywhn: tensor([[0.6930, 0.4459, 0.0221, 0.0669]], device='cuda:0')\n",
            "xyxy: tensor([[1309.2798,  445.3984, 1351.7588,  517.6505]], device='cuda:0')\n",
            "xyxyn: tensor([[0.6819, 0.4124, 0.7040, 0.4793]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8311], device='cuda:0')\n",
            "data: tensor([[359.1696, 720.3539, 394.5005, 825.0251,   0.8311,   0.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[376.8350, 772.6895,  35.3308, 104.6711]], device='cuda:0')\n",
            "xywhn: tensor([[0.1963, 0.7155, 0.0184, 0.0969]], device='cuda:0')\n",
            "xyxy: tensor([[359.1696, 720.3539, 394.5005, 825.0251]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1871, 0.6670, 0.2055, 0.7639]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.8062], device='cuda:0')\n",
            "data: tensor([[8.7233e+02, 3.6201e+02, 9.0532e+02, 4.2252e+02, 8.0616e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[888.8262, 392.2622,  32.9930,  60.5109]], device='cuda:0')\n",
            "xywhn: tensor([[0.4629, 0.3632, 0.0172, 0.0560]], device='cuda:0')\n",
            "xyxy: tensor([[872.3297, 362.0067, 905.3227, 422.5176]], device='cuda:0')\n",
            "xyxyn: tensor([[0.4543, 0.3352, 0.4715, 0.3912]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7943], device='cuda:0')\n",
            "data: tensor([[326.4586, 495.4454, 364.1342, 570.0192,   0.7943,   0.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[345.2964, 532.7323,  37.6757,  74.5738]], device='cuda:0')\n",
            "xywhn: tensor([[0.1798, 0.4933, 0.0196, 0.0690]], device='cuda:0')\n",
            "xyxy: tensor([[326.4586, 495.4454, 364.1342, 570.0192]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1700, 0.4587, 0.1897, 0.5278]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7864], device='cuda:0')\n",
            "data: tensor([[1.2767e+03, 3.9301e+02, 1.3084e+03, 4.6384e+02, 7.8635e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1292.5857,  428.4250,   31.6780,   70.8242]], device='cuda:0')\n",
            "xywhn: tensor([[0.6732, 0.3967, 0.0165, 0.0656]], device='cuda:0')\n",
            "xyxy: tensor([[1276.7467,  393.0129, 1308.4247,  463.8372]], device='cuda:0')\n",
            "xyxyn: tensor([[0.6650, 0.3639, 0.6815, 0.4295]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7824], device='cuda:0')\n",
            "data: tensor([[222.2054, 513.5491, 256.0268, 595.1774,   0.7824,   0.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[239.1161, 554.3633,  33.8214,  81.6282]], device='cuda:0')\n",
            "xywhn: tensor([[0.1245, 0.5133, 0.0176, 0.0756]], device='cuda:0')\n",
            "xyxy: tensor([[222.2054, 513.5491, 256.0268, 595.1774]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1157, 0.4755, 0.1333, 0.5511]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7763], device='cuda:0')\n",
            "data: tensor([[1.2792e+02, 9.7068e+02, 1.6830e+02, 1.0795e+03, 7.7630e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[ 148.1094, 1025.0830,   40.3791,  108.8121]], device='cuda:0')\n",
            "xywhn: tensor([[0.0771, 0.9492, 0.0210, 0.1008]], device='cuda:0')\n",
            "xyxy: tensor([[ 127.9198,  970.6769,  168.2990, 1079.4890]], device='cuda:0')\n",
            "xyxyn: tensor([[0.0666, 0.8988, 0.0877, 0.9995]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7712], device='cuda:0')\n",
            "data: tensor([[1.2284e+03, 4.3210e+02, 1.2642e+03, 5.0174e+02, 7.7120e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1246.2930,  466.9203,   35.7213,   69.6323]], device='cuda:0')\n",
            "xywhn: tensor([[0.6491, 0.4323, 0.0186, 0.0645]], device='cuda:0')\n",
            "xyxy: tensor([[1228.4323,  432.1042, 1264.1536,  501.7365]], device='cuda:0')\n",
            "xyxyn: tensor([[0.6398, 0.4001, 0.6584, 0.4646]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7647], device='cuda:0')\n",
            "data: tensor([[591.1613, 589.1539, 631.5229, 672.9655,   0.7647,   0.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[611.3421, 631.0597,  40.3617,  83.8116]], device='cuda:0')\n",
            "xywhn: tensor([[0.3184, 0.5843, 0.0210, 0.0776]], device='cuda:0')\n",
            "xyxy: tensor([[591.1613, 589.1539, 631.5229, 672.9655]], device='cuda:0')\n",
            "xyxyn: tensor([[0.3079, 0.5455, 0.3289, 0.6231]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7580], device='cuda:0')\n",
            "data: tensor([[1.8502e+03, 8.0797e+02, 1.8942e+03, 9.2062e+02, 7.5805e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1872.2007,  864.2930,   43.9790,  112.6454]], device='cuda:0')\n",
            "xywhn: tensor([[0.9751, 0.8003, 0.0229, 0.1043]], device='cuda:0')\n",
            "xyxy: tensor([[1850.2112,  807.9703, 1894.1902,  920.6157]], device='cuda:0')\n",
            "xyxyn: tensor([[0.9637, 0.7481, 0.9866, 0.8524]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7555], device='cuda:0')\n",
            "data: tensor([[375.3304, 306.0680, 400.7169, 366.3661,   0.7555,   0.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[388.0236, 336.2171,  25.3865,  60.2982]], device='cuda:0')\n",
            "xywhn: tensor([[0.2021, 0.3113, 0.0132, 0.0558]], device='cuda:0')\n",
            "xyxy: tensor([[375.3304, 306.0680, 400.7169, 366.3661]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1955, 0.2834, 0.2087, 0.3392]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7395], device='cuda:0')\n",
            "data: tensor([[1.1579e+03, 3.5625e+02, 1.1874e+03, 4.1237e+02, 7.3954e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1172.6444,  384.3119,   29.5442,   56.1160]], device='cuda:0')\n",
            "xywhn: tensor([[0.6108, 0.3558, 0.0154, 0.0520]], device='cuda:0')\n",
            "xyxy: tensor([[1157.8723,  356.2539, 1187.4165,  412.3699]], device='cuda:0')\n",
            "xyxyn: tensor([[0.6031, 0.3299, 0.6184, 0.3818]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.7214], device='cuda:0')\n",
            "data: tensor([[7.7529e+02, 4.1636e+02, 8.0589e+02, 4.9240e+02, 7.2143e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[790.5908, 454.3808,  30.5922,  76.0446]], device='cuda:0')\n",
            "xywhn: tensor([[0.4118, 0.4207, 0.0159, 0.0704]], device='cuda:0')\n",
            "xyxy: tensor([[775.2947, 416.3585, 805.8869, 492.4031]], device='cuda:0')\n",
            "xyxyn: tensor([[0.4038, 0.3855, 0.4197, 0.4559]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.6238], device='cuda:0')\n",
            "data: tensor([[1.1237e+03, 7.0741e+02, 1.1783e+03, 7.9319e+02, 6.2379e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1150.9806,  750.3024,   54.6321,   85.7802]], device='cuda:0')\n",
            "xywhn: tensor([[0.5995, 0.6947, 0.0285, 0.0794]], device='cuda:0')\n",
            "xyxy: tensor([[1123.6646,  707.4124, 1178.2966,  793.1925]], device='cuda:0')\n",
            "xyxyn: tensor([[0.5852, 0.6550, 0.6137, 0.7344]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.6187], device='cuda:0')\n",
            "data: tensor([[7.7661e+02, 3.6807e+02, 8.0287e+02, 4.2647e+02, 6.1875e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[789.7399, 397.2688,  26.2603,  58.3965]], device='cuda:0')\n",
            "xywhn: tensor([[0.4113, 0.3678, 0.0137, 0.0541]], device='cuda:0')\n",
            "xyxy: tensor([[776.6098, 368.0706, 802.8701, 426.4671]], device='cuda:0')\n",
            "xyxyn: tensor([[0.4045, 0.3408, 0.4182, 0.3949]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([32.], device='cuda:0')\n",
            "conf: tensor([0.6069], device='cuda:0')\n",
            "data: tensor([[1.1864e+03, 8.4942e+02, 1.2046e+03, 8.6635e+02, 6.0691e-01, 3.2000e+01]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1195.5062,  857.8861,   18.2432,   16.9314]], device='cuda:0')\n",
            "xywhn: tensor([[0.6227, 0.7943, 0.0095, 0.0157]], device='cuda:0')\n",
            "xyxy: tensor([[1186.3846,  849.4204, 1204.6278,  866.3518]], device='cuda:0')\n",
            "xyxyn: tensor([[0.6179, 0.7865, 0.6274, 0.8022]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.5019], device='cuda:0')\n",
            "data: tensor([[1.0333e+03, 9.3127e+02, 1.0753e+03, 1.0537e+03, 5.0191e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1054.2806,  992.4906,   41.9397,  122.4368]], device='cuda:0')\n",
            "xywhn: tensor([[0.5491, 0.9190, 0.0218, 0.1134]], device='cuda:0')\n",
            "xyxy: tensor([[1033.3108,  931.2722, 1075.2505, 1053.7090]], device='cuda:0')\n",
            "xyxyn: tensor([[0.5382, 0.8623, 0.5600, 0.9757]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.4950], device='cuda:0')\n",
            "data: tensor([[1.1510e+03, 7.2847e+02, 1.1989e+03, 7.9645e+02, 4.9504e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1174.9830,  762.4608,   47.9060,   67.9763]], device='cuda:0')\n",
            "xywhn: tensor([[0.6120, 0.7060, 0.0250, 0.0629]], device='cuda:0')\n",
            "xyxy: tensor([[1151.0300,  728.4727, 1198.9360,  796.4489]], device='cuda:0')\n",
            "xyxyn: tensor([[0.5995, 0.6745, 0.6244, 0.7375]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.], device='cuda:0')\n",
            "conf: tensor([0.3748], device='cuda:0')\n",
            "data: tensor([[1.9026e+03, 3.7755e+02, 1.9193e+03, 4.4308e+02, 3.7479e-01, 0.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[1910.9414,  410.3139,   16.6721,   65.5351]], device='cuda:0')\n",
            "xywhn: tensor([[0.9953, 0.3799, 0.0087, 0.0607]], device='cuda:0')\n",
            "xyxy: tensor([[1902.6053,  377.5464, 1919.2775,  443.0815]], device='cuda:0')\n",
            "xyxyn: tensor([[0.9909, 0.3496, 0.9996, 0.4103]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "iyTZnTg4R8qp",
        "outputId": "23d0907a-0dda-4df0-e391-f476e35fbddd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.34-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m847.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Installing collected packages: python-magic, python-dotenv, chardet, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "Successfully installed chardet-4.0.0 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.34\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet"
                ]
              },
              "id": "34cd09e9073f4f7bad46f5aaece33c89"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"UTPnCuzCsB7pFBGSNWg4\")\n",
        "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-players-detection-3zvbc\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-sDYN91R_kE",
        "outputId": "caeb37d0-9ae7-4ac4-fe55-926027c475cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in football-players-detection-1 to yolov5pytorch:: 100%|██████████| 148663/148663 [00:02<00:00, 50066.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to football-players-detection-1 in yolov5pytorch:: 100%|██████████| 1338/1338 [00:00<00:00, 2323.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.move('football-players-detection-1/train','football-players-detection-1/football-players-detection-1/train')\n",
        "shutil.move('football-players-detection-1/test',\n",
        "            'football-players-detection-1/football-players-detection-1/test')\n",
        "\n",
        "shutil.move('football-players-detection-1/valid',\n",
        "            'football-players-detection-1/football-players-detection-1/valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "um9AkNL1ScyS",
        "outputId": "25570b66-bfd3-4a90-b2d3-9706afdf7ec9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'football-players-detection-1/football-players-detection-1/valid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov5x.pt data={dataset.location}/data.yaml epochs=100 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd_EpFQLSf0v",
        "outputId": "de0739ed-957e-4752-9fa8-8ef2a12495fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP 💡 Replace 'model=yolov5x.pt' with new 'model=yolov5xu.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5xu.pt to 'yolov5xu.pt'...\n",
            "100% 186M/186M [00:00<00:00, 348MB/s]\n",
            "Ultralytics YOLOv8.2.58 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5x.pt, data=/content/football-players-detection-1/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 22.1MB/s]\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      8800  ultralytics.nn.modules.conv.Conv             [3, 80, 6, 2, 2]              \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  4    309120  ultralytics.nn.modules.block.C3              [160, 160, 4]                 \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  8   2259200  ultralytics.nn.modules.block.C3              [320, 320, 8]                 \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1 12  13125120  ultralytics.nn.modules.block.C3              [640, 640, 12]                \n",
            "  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n",
            "  8                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4]               \n",
            "  9                  -1  1   4099840  ultralytics.nn.modules.block.SPPF            [1280, 1280, 5]               \n",
            " 10                  -1  1    820480  ultralytics.nn.modules.conv.Conv             [1280, 640, 1, 1]             \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  4   5332480  ultralytics.nn.modules.block.C3              [1280, 640, 4, False]         \n",
            " 14                  -1  1    205440  ultralytics.nn.modules.conv.Conv             [640, 320, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  4   1335040  ultralytics.nn.modules.block.C3              [640, 320, 4, False]          \n",
            " 18                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  4   4922880  ultralytics.nn.modules.block.C3              [640, 640, 4, False]          \n",
            " 21                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4, False]        \n",
            " 24        [17, 20, 23]  1  11025820  ultralytics.nn.modules.head.Detect           [4, [320, 640, 1280]]         \n",
            "YOLOv5x summary: 493 layers, 97,203,260 parameters, 97,203,244 gradients, 246.9 GFLOPs\n",
            "\n",
            "Transferred 817/823 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.25M/6.25M [00:00<00:00, 99.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/football-players-detection-1/football-players-detection-1/train/labels... 612 images, 0 backgrounds, 0 corrupt: 100% 612/612 [00:00<00:00, 1841.68it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/football-players-detection-1/football-players-detection-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/football-players-detection-1/football-players-detection-1/valid/labels... 38 images, 0 backgrounds, 0 corrupt: 100% 38/38 [00:00<00:00, 852.57it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/football-players-detection-1/football-players-detection-1/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 135 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/39 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      1/100      15.4G      1.444      4.342     0.8766        609        640:  18% 7/39 [00:13<01:03,  1.97s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 708, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 652, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 204, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 381, in _do_train\n",
            "    self.loss, self.loss_items = self.model(batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 101, in forward\n",
            "    return self.loss(x, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 283, in loss\n",
            "    return self.criterion(preds, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py\", line 231, in __call__\n",
            "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py\", line 72, in forward\n",
            "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py\", line 92, in get_pos_mask\n",
            "    mask_in_gts = self.select_candidates_in_gts(anc_points, gt_bboxes)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tal.py\", line 227, in select_candidates_in_gts\n",
            "    bbox_deltas = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]), dim=2).view(bs, n_boxes, n_anchors, -1)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 122.00 MiB. GPU \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7u_uGHkSjlU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}